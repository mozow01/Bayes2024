# Gr√°fmodellek

A gr√°fmodell alapj√°ul szolg√°l√≥ _G_ ir√°ny√≠tott k√∂rmentes gr√°f (DAG) egy sp√©ci c√≠mk√©zett oszt√°lyba tarozik. A **bekarik√°zott** cs√∫csok val√≥sz√≠n≈±s√©gi v√°ltoz√≥kat reprezent√°lnak (√©s el√©g ezeket felt√ºntetni, de nem kell csak ezeket), a **bekarik√°zatlanok** determinisztikus v√°ltoz√≥kat. A **nyilak** a p(x<sub>0</sub>,...,x<sub>K</sub>) joint val√≥sz√≠n≈±s√©g al√°bbi alak√∫ szorzatt√° bonthat√≥s√°g√°t fejezi ki valamilyen √©rtelemben:

[![\\ \Pr(x_1,\ldots,x_K)=\prod_{i=1}^K \Pr(x_i\mid\text{pare}(x_i)) \\ ](https://latex.codecogs.com/svg.latex?%5C%5C%20%5CPr(x_1%2C%5Cldots%2Cx_K)%3D%5Cprod_%7Bi%3D1%7D%5EK%20%5CPr(x_i%5Cmid%5Ctext%7Bpare%7D(x_i))%20%5C%5C%20)](#_)

ahol pa<sub>k</sub> az x<sub>k</sub> cs√∫cs (k√∂zvetlen) sz√ºlei. A szorzatban pontosan akkor szerepel a p(x<sub>k</sub> | x<sub>i</sub>,...,x<sub>j</sub>) t√©nyez≈ë, ha a G-ben van x<sub>i</sub>,...,x<sub>j</sub> pontjaib√≥l x<sub>k</sub>-ba mutat√≥ ny√≠l. A **besat√≠rozott** cs√∫csok olyan val√≥sz√≠n≈±s√©gi v√°ltoz√≥k, amelyek a **megfigyelt v√°ltoz√≥kat reprezent√°lj√°k.** A **nem besat√≠rozott** v√°ltoz√≥k a **l√°tens param√©terek.** Teh√°t G gr√°fmondellje a p(x<sub>0</sub>,...x<sub>K</sub>) joint val√≥sz√≠n≈±s√©gnek, ha a fenti faktoriz√°ci√≥s tulajdons√°g teljes√ºl.

A faktorit√°ci√≥s tulajdos√°got t√©nylegesen jeleznii tudjuk a **faktorpontokkal.** Ekkor pontosan akkor k√∂ti √∂ssze egy faktorpont egy gyerekeket √©s sz√ºl≈ëket, ha ezekt≈ël f√ºgg a gyerek.

## Diszkr√©t hierarchikus modell (√©vszak √©s vizes f≈±)

A _generat√≠v modell_ (azaz egy "randomoutput(randominput)" algoritmikus f√ºggv√©ny) n√©gy val√≥sz√≠n≈±s√©gi v√°ltoz√≥b√≥l √°ll el≈ë, "√©vszak" (h) (tavasz/ny√°r/≈ësz/t√©l) , "felh≈ës" (f) (der≈±s/enyh√©n felh≈ës/er≈ësen felh≈ës), "locsol√≥rendszer" (l) (megy/nem megy), "es≈ë" (e) (esik/nem esik), "vizes a f≈±" (v) (vizes/nem vizes). Ezek az al√°bbi gr√°f alapj√°n f√ºggnek egym√°st√≥l (a faktorok val√≥ban azt jelzik, hogy a joint val√≥sz√≠n≈±s√©g hogyan bomlik szorzat√°).

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/locsolo_1.png" width=600>

√âs a webppl k√≥d:

````javascript
var vizesModel = Infer({ method: 'enumerate' }, function(){
  var √©vszak = categorical({ps:[0.25,0.25,0.25,0.25], 
                            vs: ['tavasz', 'ny√°r', '≈ësz', 't√©l'] });
  
  var felh≈ës = ((√©vszak === 'tavasz') || (√©vszak === '≈ësz' )) ? flip(0.9) : flip(0.5);
  
  var esik = felh≈ës ? flip(0.8) : flip(0.0);
 
  var locsol√≥ = felh≈ës ? flip(0.1) : flip(0.9);
  
  var vizes = esik && locsol√≥ 
                   ? flip(.99)  
                   : (esik && !locsol√≥ ) || (esik && !locsol√≥ ) 
                        ? flip(0.9) 
                        : flip(0.1);
       condition(vizes === true);
  
  var √©vszakPrior = categorical({ps:[0.25,0.25,0.25,0.25], 
                            vs: ['tavasz', 'ny√°r', '≈ësz', 't√©l'] });
  
  var felh≈ësPrior = ((√©vszakPrior === 'tavasz') || (√©vszakPrior === '≈ësz' )) ? 
      flip(0.9) : flip(0.5);
  
       return {√©vszakPrior: √©vszakPrior, felh≈ësPrior: felh≈ësPrior,
               √©vszakPost: √©vszak, felh≈ësPost: felh≈ës  };
});

viz.marginals(vizesModel)
````

Itt "√©vszak" el≈ëtt van egy konstans cs√∫cs, ami a kategorikus v√°ltoz√≥ eloszl√°s√°nak adatait (hogy egyenletes) tartalmazza. Ezek a param√©terek azonban r√∂gz√≠tettek.

A generat√≠v modell programozott verzi√≥ja a fenti k√≥dban ez (A pszeudok√≥dj√°t az √°br√°n l√°tjuk.)

````javascript
var √©vszak = categorical({ps:[0.25,0.25,0.25,0.25], vs: ['tavasz', 'ny√°r', '≈ësz', 't√©l'] });

var felh≈ës = ((√©vszak === 'tavasz') || (√©vszak === '≈ësz' )) ? flip(0.9) : flip(0.5);
  
var esik = felh≈ës ? flip(0.8) : flip(0.0);
 
var locsol√≥ = felh≈ës ? flip(0.1) : flip(0.9);
  
var vizes = esik && locsol√≥ 
                   ? flip(.99)  
                   : (esik && !locsol√≥ ) || (esik && !locsol√≥ ) 
                        ? flip(0.9) 
                        : flip(0.1);
````
M√∫lhatatlanul fontos a Bayes-t√©tel:

[![\\ \Pr(\vartheta)\;\leadsto\;\Pr(\vartheta\mid X )=\dfrac{\Pr(X\mid \vartheta)\cdot \Pr(\vartheta)}{\Pr(X)}\;;\Pr(\vartheta=t\mid X=d )=\dfrac{\Pr(X=d\mid \vartheta=t)\cdot \Pr(\vartheta=t)}{\Pr(X=d)}](https://latex.codecogs.com/svg.latex?%5C%5C%20%5CPr(%5Cvartheta)%5C%3B%5Cleadsto%5C%3B%5CPr(%5Cvartheta%5Cmid%20X%20)%3D%5Cdfrac%7B%5CPr(X%5Cmid%20%5Cvartheta)%5Ccdot%20%5CPr(%5Cvartheta)%7D%7B%5CPr(X)%7D%5C%3B%3B%5CPr(%5Cvartheta%3Dt%5Cmid%20X%3Dd%20)%3D%5Cdfrac%7B%5CPr(X%3Dd%5Cmid%20%5Cvartheta%3Dt)%5Ccdot%20%5CPr(%5Cvartheta%3Dt)%7D%7B%5CPr(X%3Dd)%7D)](#_)

Itt 

P(ùúó|X) a **poszterior eloszl√°s,** 

P(X|ùúó) a **likelihood f√ºggv√©ny,**

P(ùúó) a **prior eloszl√°s,**

P(X) az **adat val√≥sz√≠n≈±s√©ge**.

Ez ut√≥bbi kett≈ë margin√°lis eloszl√°sok: 

[![\\ \Pr(\vartheta=t)=\sum\limits_{X=d}\Pr(\vartheta=t,X=d)](https://latex.codecogs.com/svg.latex?%5C%5C%20%5CPr(%5Cvartheta%3Dt)%3D%5Csum%5Climits_%7BX%3Dd%7D%5CPr(%5Cvartheta%3Dt%2CX%3Dd))](#_)

[![\\ \Pr(X=d)=\sum\limits_{\vartheta=t}\Pr(\vartheta=t,X=d)](https://latex.codecogs.com/svg.latex?%5C%5C%20%5CPr(X%3Dd)%3D%5Csum%5Climits_%7B%5Cvartheta%3Dt%7D%5CPr(%5Cvartheta%3Dt%2CX%3Dd))](#_)
 
Bizony√≠t√°s:

[![\\ \Pr(\vartheta=t,X=d)=\Pr(\vartheta=t\mid X=d )\cdot \Pr(X=d)\\ \\ \Pr(X=d,\vartheta=t)=\Pr(X=d\mid \vartheta=t )\cdot \Pr(\vartheta=t\)](https://latex.codecogs.com/svg.latex?%5C%5C%20%5CPr(%5Cvartheta%3Dt%2CX%3Dd)%3D%5CPr(%5Cvartheta%3Dt%5Cmid%20X%3Dd%20)%5Ccdot%20%5CPr(X%3Dd)%5C%5C%20%5C%5C%20%5CPr(X%3Dd%2C%5Cvartheta%3Dt)%3D%5CPr(X%3Dd%5Cmid%20%5Cvartheta%3Dt%20)%5Ccdot%20%5CPr(%5Cvartheta%3Dt%5C))](#_)

√âs persze a joint eloszl√°sokra: P(X,ùúó)=P(ùúó,X). Qed.

A **p√©ldabeli** joint eloszl√°s faktoriz√°ci√≥ja teh√°t a k√∂vetkez≈ë: 

[![\\ \\ \begin{align*} \\ p(h,f,l,e,v) &=p(v|l,e)\cdot p(l,e)= \qquad (\;p(h,l,f,e|v)\cdot p(v)\;)\\ \\ &= p(v|f,e)\cdot p(l,e|f)\cdot p(f)=\\ \\ &=p(v|f,e)\cdot p(l|f)\cdot p(e|f)\cdot p(f|h) \cdot p(h) \\ \end{alogn*}](https://latex.codecogs.com/svg.latex?%5C%5C%20%5C%5C%20%5Cbegin%7Balign*%7D%20%5C%5C%20p(h%2Cf%2Cl%2Ce%2Cv)%20%26%3Dp(v%7Cl%2Ce)%5Ccdot%20p(l%2Ce)%3D%20%5Cqquad%20(%5C%3Bp(h%2Cl%2Cf%2Ce%7Cv)%5Ccdot%20p(v)%5C%3B)%5C%5C%20%5C%5C%20%26%3D%20p(v%7Cf%2Ce)%5Ccdot%20p(l%2Ce%7Cf)%5Ccdot%20p(f)%3D%5C%5C%20%5C%5C%20%26%3Dp(v%7Cf%2Ce)%5Ccdot%20p(l%7Cf)%5Ccdot%20p(e%7Cf)%5Ccdot%20p(f%7Ch)%20%5Ccdot%20p(h)%20%5C%5C%20%5Cend%7Balogn*%7D)](#_)

A p(l,e,f,h) ~> p(l,e,f,h|v) **Bayes-friss√≠t√©s** v√©geredm√©nye, azaz a poszterior eloszl√°st a Bayes-t√©tel alapj√°n kapjuk:
 
[![\\ \;p(l,e,f,h|v)=\dfrac{p(v|l,e)\cdot p(l|f)\cdot p(e|f)\cdot p(f|h)\cdot p(h)}{p(v)}](https://latex.codecogs.com/svg.latex?%5C%5C%20%5C%3Bp(l%2Ce%2Cf%2Ch%7Cv)%3D%5Cdfrac%7Bp(v%7Cl%2Ce)%5Ccdot%20p(l%7Cf)%5Ccdot%20p(e%7Cf)%5Ccdot%20p(f%7Ch)%5Ccdot%20p(h)%7D%7Bp(v)%7D)](#_)

Itt a **likelihood f√ºggv√©ny,** p(v|l,e) p(l|f) p(e|f) p(f|h) (mondjuk), vagyis az a f√ºggv√©ny, megadja a generat√≠v modellt, √©s ez m√©g a priorral val√≥ szorz√°s ut√°n sem lesz igazi val√≥sz√≠n≈±s√©gi eloszl√°s, de az adat r√∂gz√≠t√©s√©vel (m√°rpedig az adatok r√∂gz√≠tettek), ar√°nyos lesz ezzel. Az ar√°nyoss√°gi t√©nyez≈ë 1/p(v), amivel norm√°ljuk a likelihood-prior szorzatot, √©s az m√°r eloszl√°s lesz.

(A Bayes-inferencia most "kimer√≠t√©ssel" (enumerate) √©s "az adat felt√©telez√©s√©vel" (condition) m≈±k√∂dik: a h√≥nap v√°ltoz√≥ margin√°lis eloszl√°s√°t sz√°molja ki azzal a felt√©tellel, hogy adat = vizes, az √∂sszes eset v√©gigsz√°mol√°s√°val.)

## Konjug√°lt prior

Nyilv√°nval√≥, hogy a **jelens√©get** a generat√≠v modell tartalmazza, ami pedig a likelihood f√ºggv√©nyt sz√°molja ki valamilyen m√≥don. Ez most az egyszer≈±s√©g√©ben is el√©g bonyi, de maradjunk annyiban, hogy valami kategorikus v√°ltoz√≥ a bemenet √©s Boole-√©rt√©k≈± a kimenet. Az elemz√©st tov√°bb finom√≠thatjuk √∫gy, hogy a prior param√©tereit vari√°ljuk. Most a prior egy egyszer≈± **kategorikus** v√°ltoz√≥: egy zs√°kban sz√≠nes goly√≥k vannak r√∂gz√≠tett ar√°nyban √©s egy goly√≥t h√∫zunk bel≈ële. A prior param√©tereire tett elm√©leti felt√©telez√©st hiperpriornak nevezz√ºk. 

Hogyan v√°lasztunk hiperpriort (vagy √°ltal√°ban priort)?  

B√°rhogy. De ha sz√©p eredm√©nyt akarunk, akkor a likelihoodhoz (vagyis az alapjelens√©ghez) olyan hiperprior eloszl√°st (m√°sik jelens√©get) kell v√°lasztanunk, amivel ha a likelihood-ot megszorozzuk ugyanolyan jelens√©get kapunk, mint a hiperprior. Ez az√©rt van, mert azt gondoljuk, hogy a Bayes-i update-el√©s val√≥ban √©les√≠t√©s: egy y |----> f(p,y) (prior) f√ºggv√©nycsal√°db√≥l v√°lasztja ki azt a p param√©tert, amit az adatok mellett a legval√≥sz√≠n≈±bb. Nem kell felt√©tlen√ºl √≠gy tenn√ºnk, mert √∫gy is numerikus a sz√°m√≠t√°s √©s a g√©p kidobja az eloszl√°st mindenk√©ppen. De ez az aj√°nl√°s, nem teljesen h√ºlyes√©g. 

[https://en.wikipedia.org/wiki/Conjugate_prior]

P√©ld√°ul a kategorikus v√°ltoz√≥ sz√°m√°ra a konjug√°lt prior a _Dirichlet-eloszl√°s._ A binomi√°lis ("h√°nyan hib√°ztak r√° a j√≥ v√°laszra") v√°ltoz√≥hoz a beta. A beta √°ltal√°nos√≠t√°sa a Dirichlet. A gauss-nak a gauss.

A locsol√≥s p√©lda ezzel m√≥dos√≠tva:

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/locsolo_2.png" width=600>

√âs a k√≥d:

````javascript
var vizesmasikModel = Infer({ method: 'rejection' }, function(){
  
  var x = dirichlet({alpha: Vector([1/10,2/10,7/10])});

    var x1 = (x.data)[0];

    var x2 = (x.data)[1];

    var x3 = (x.data)[2];
  
  var felh≈ës =  categorical({ps:[x1,x2,x3], 
                            vs: ['der√ºlt', 'enyh√©n felh≈ës', 'er≈ësen felh≈ës'] });
  
  var esik = (felh≈ës === 'der√ºlt')
                   ? flip(.1)  
                   : (felh≈ës === 'enyh√©n felh≈ës')
                        ? flip(0.6) 
                        : flip(0.9);
 
  var locsol√≥ = (felh≈ës === 'der√ºlt')
                   ? flip(.9)  
                   : (felh≈ës === 'enyh√©n felh≈ës')
                        ? flip(0.2) 
                        : flip(0);
  
  var vizes = esik && locsol√≥ 
                   ? flip(.99)  
                   : (esik && !locsol√≥ ) || (esik && !locsol√≥ ) 
                        ? flip(0.9) 
                        : flip(0.1);
       condition(vizes === true);
  
  var y = dirichlet({alpha: Vector([1/10,2/10,7/10])});
   
    var y1 = (y.data)[0];

    var y2 = (y.data)[1];

    var y3 = (y.data)[2];
  
  var felh≈ësPrior = categorical({ps:[y1,y2,y3], 
                            vs: ['der√ºlt', 'enyh√©n felh≈ës', 'er≈ësen felh≈ës'] });
  
  
       return {der≈±sHyperPrior: y1, enyhenHyperPrior2: y2, er√∂senHyperPrior: y3, 
               felh≈ësPrior: felh≈ësPrior,
               felh≈ësPosterior: felh≈ës  };
});

viz.marginals(vizesmasikModel)
````

# P√©ld√°k

## Binomi√°lis k√≠s√©rlet k√ºl√∂nb√∂z≈ë m√©ret≈± csoportokkal

H√°rom k√ºl√∂nb√∂z≈ë csoportban k√©rdezt√©k meg, hogy a pillang√≥ vir√°g-e, a m√©rt v√°ltoz√≥ √©rt√©kei a data v√°ltoz√≥ alatt tal√°lhat√≥k. A k√©t modellben a priorok a non-informative √©s a dogmatikus volt. 

### Egyenletes prior

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/binom_1.png" width=500>

````javascript
var data = [{name: 'napocskas', n:20, k:5},
            {name: 'holdacskas', n:23, k:8},
            {name: 'napraforgo', n:19, k:17},
           ]

var simpleModel = function() {
  
  var p = uniform(0,1);
  
  map(function(d){observe(Binomial({p: p, n: d.n}), d.k)}, data);
  
  var prior = uniform(0,1);
  
  // 20 f≈ës csoportokra norm√°lva
  
  var predictivePosterior = binomial({p: p, n: 20});
  
  var predictivePrior = binomial({p: prior, n: 20});
  
  return {Prior: prior, 
          PredictivePrior: predictivePrior, 
          Posterior: p, 
          PredictivePosterior: predictivePosterior};
}

var opts = {method: 'MCMC', samples: 20000}

var output_1 = Infer(opts, simpleModel)

viz.marginals(output_1)
````

Teh√°t az adatot a **map** k√∂rnyezetbe √°gyazva illesztj√ºk be a felt√©telbe.

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/1559f8.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/30810f.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/bab66f.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/d0c66b.svg" height=200>

### Beta prior


<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/binom_2.png" width=500>

````javascript
var data = [{name: 'napocskas', n:20, k:5},
            {name: 'holdacskas', n:23, k:8},
            {name: 'napraforgo', n:19, k:17},
           ]

var complexModel = function() {
  
  var p = beta(30,90);
  
  map(function(d){observe(Binomial({p: p, n: d.n}), d.k)}, data);
  
  var prior = beta(30,90);
  
    // 20 f≈ës csoportokra norm√°lva
  
  var predictivePosterior = binomial({p: p, n: 20});
  
  var predictivePrior = binomial({p: prior, n: 20});
  
  return {Prior: prior, 
          PredictivePrior: predictivePrior, 
          Posterior: p, 
          PredictivePosterior: predictivePosterior};
}

var opts = {method: 'MCMC', samples: 20000}

var output_2 = Infer(opts, complexModel)

viz.marginals(output_2)
````

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/641286.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/6af94a.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/28e8ec.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/af2eb4.svg" height=200>


## Aranyhal

Egy aranyhal s√∫lyadatai: 5, 16 √©s 17 g, h√°rom m√©r√©s ut√°n. √ögy d√∂nt√ºnk, hogy ha az √°tlag a 15-17 s√°vba esik, akkor √°tlagos mennys√©get adunk neki, ha kevesebb, akkor t√∂bbet, ha t√∂bb, akkor kevesebbet. A k√©rd√©s, hogy sz√°mtani k√∂zepet sz√°moljunk-e (12.7 g) vagy (informat√≠v) priorb√≥l dolgozzunk-e. A komplexebb megk√∂zel√≠t√©shez tudjuk, hogy ezen halfajta s√∫lya (x) norm√°l eloszl√°st mutat, az √°tlaga 16 g, ennek az adatnak a sz√≥r√°sa 0.2 g, tov√°bb√° az x norm√°l elszol√°s√°nak sz√≥r√°sa 1 g. 

Ebben a p√©ld√°ban, l√©v√©n a likelihood folytonos eloszl√°s, **nem haszn√°lhatjuk a diszkr√©t eloszl√°sok felt√©teleit tartalamz√≥ condition-t,** mert az hajsz√°lpontos √©rt√©ket √ºtk√∂ztet. Helyette az **observe** parancs laz√≠t az adatok √ºtk√∂ztet√©s√©n. Ekkor el√©g, ha a gener√°lt adatok a megfigyelt adatok egy kis k√∂rnyezet√©ben vannak. L√°sd: [https://webppl.readthedocs.io/en/master/inference/conditioning.html]

### Megold√°s. 

#### Ha a prior uniform: 

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/gaussunif_1.png" width=500>

````javascript
var data = [{k: 5},
            {k: 16},
            {k: 17},
           ]

var simpleModel = function() {
  
  var m = uniform(4,18);
   
  map(function(d){observe(Gaussian({mu: m, sigma: 1}),d.k)},data);
  
  var Prior = uniform(4,18);
  
  var PredictivePosterior = gaussian(m,1);
  
  return {
          Prior: Prior, 
          Posterior: m,
          PosteriorPredictive: PredictivePosterior
         };
}

var opts = {method: 'SMC', particles: 2000, rejuvSteps: 5}

var output_1 = Infer(opts, simpleModel)

viz.marginals(output_1)
````
<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/260332.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/3777e1.svg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/7e1f19.svg" height=200>

#### Komplexebb modell:

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/gauss_dogm.png" width=500>


````javascript
var data = [{k: 5},
            {k: 16},
            {k: 17},
           ]

var complexModel = function() {
  
  var m = gaussian(16,0.2);
  
  map(function(d){observe(Gaussian({mu: m, sigma: 1}),d.k)},data);
  
  var Prior = gaussian(16,0.2);
  
  var PredictivePosterior = gaussian(m,1);
  
  return {
           Prior: Prior, 
           Posterior: m,
           PosteriorPredictive: PredictivePosterior};
}

var opts = {method: 'SMC', particles: 2000, rejuvSteps: 5}

var output_2 = Infer(opts, complexModel)

viz.marginals(output_2)

````

<img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/8628b1.jpg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/28c592.jpg" height=200><img src="https://github.com/mozow01/cog_compsci/blob/main/orak/files/1f1af8.jpg" height=200>

K√∂z√∂s h√°zi:

1.) K√©sz√≠ts√ºk el az al√°bbiak webppl k√≥dj√°t!

<img src="https://github.com/mozow01/Bayes2024/blob/main/japan.png" height=200>

2.) Egy tengerparton homokos √©s s√≥deros partszakasz is van. A sir√°lyok sz√≠vesebben id≈ëznek a s√≥deroson. K√©sz√≠ts√ºnk generat√≠v modellt, amelyik gener√°lja az adatokat! Ha el k√©ne d√∂nteni, hogy egy l√©tez≈ë jelens√©g-e, akkor milyen k√©t modellt √ºtk√∂ztetn√©nk?

````
var model = function() {
  
  var i = categorical({ps:[0.5,0.5], 
                            vs: ['modell', 'null modell']});
   
  
  var p = (i==="modell") ? beta(10,1) : beta(50,50);
  
    observe(Binomial({p : p, n: 20}), 15);

return {i: i, p : p};
};

var output = Infer({model: model, samples: 1000, method: 'MCMC'});

viz.marginals(output);
````

